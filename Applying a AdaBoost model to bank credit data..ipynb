{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a AdaBoost model to bank credit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "## We will create the features and labels from the Germna bnak credit dataset.\n",
    "\n",
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will do a 10-fold cross validation to estimate the optimal hyperparameters and perform model selection. \n",
    "## We also define the inside and outside fold objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We estimate the best hyperparameters using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}\n",
    "## Define the AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(Features, Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We next perform the outer cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.758\n",
      "SDT of the metric       = 0.034\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.765\n",
      "Fold  2    0.721\n",
      "Fold  3    0.704\n",
      "Fold  4    0.736\n",
      "Fold  5    0.788\n",
      "Fold  6    0.772\n",
      "Fold  7    0.728\n",
      "Fold  8    0.827\n",
      "Fold  9    0.765\n",
      "Fold 10    0.771\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we split the data into create training and testing datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is now time to define an AdaBoosted tree model object using the estimated optimal model hyperparameters and then fits the model to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       176                36\n",
      "Actual negative        45                43\n",
      "\n",
      "Accuracy        0.73\n",
      "AUC             0.76\n",
      "Macro precision 0.67\n",
      "Macro recall    0.66\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.80          0.54\n",
      "Recall       0.83          0.49\n",
      "F1           0.81          0.51\n"
     ]
    }
   ],
   "source": [
    "## Finally we score and print evaluation metrics for the model, using the test data subset. \n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ab_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this dataset, the majority of the custmers are good credit ones. We undersample the majority case, and create a dataset with balanced cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 300]\n",
      "(600, 35)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "# The count of unique label values and the shape of the resulting arrays is printed. \n",
    "temp_Labels_1 = Labels[Labels == 1]  # Save these\n",
    "temp_Features_1 = Features[Labels == 1,:] # Save these\n",
    "temp_Labels_0 = Labels[Labels == 0]  # Undersample these\n",
    "temp_Features_0 = Features[Labels == 0,:] # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "temp_Features = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "temp_Labels = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(temp_Labels))\n",
    "print(temp_Features.shape)\n",
    "print(temp_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we perform model selection and evaluation using nested cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "nr.seed(1234)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(3214)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "## Define the AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(temp_Features, temp_Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the outer loop of the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.758\n",
      "SDT of the metric       = 0.034\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.765\n",
      "Fold  2    0.721\n",
      "Fold  3    0.704\n",
      "Fold  4    0.736\n",
      "Fold  5    0.788\n",
      "Fold  6    0.772\n",
      "Fold  7    0.728\n",
      "Fold  8    0.827\n",
      "Fold  9    0.765\n",
      "Fold 10    0.771\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in the next step, we train and evaluate a model with the balanced cases and the update hyperparameter. We create Bernoulli sampled test and training subsets.\n",
    "## We Define an AdaBoosted model and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212 212]\n",
      "(424, 35)\n",
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "## Undersample the majority case for the training data\n",
    "temp_Labels_1 = y_train[y_train == 1]  # Save these\n",
    "temp_Features_1 = X_train[y_train == 1,:] # Save these\n",
    "temp_Labels_0 = y_train[y_train == 0]  # Undersample these\n",
    "temp_Features_0 = X_train[y_train == 0,:] # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "X_train = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "y_train = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(y_train))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.1, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we define and fit an Ada Boost model.\n",
    "\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       146                66\n",
      "Actual negative        19                69\n",
      "\n",
      "Accuracy        0.72\n",
      "AUC             0.79\n",
      "Macro precision 0.70\n",
      "Macro recall    0.74\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.88          0.51\n",
      "Recall       0.69          0.78\n",
      "F1           0.77          0.62\n"
     ]
    }
   ],
   "source": [
    "probabilities = ab_mod.predict_proba(X_test)  \n",
    "print_metrics(y_test, probabilities, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
